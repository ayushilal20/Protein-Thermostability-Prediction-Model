{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/MyDrive/\n"
      ],
      "metadata": {
        "id": "ddN0xgdTr65X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f9bae5-e74b-48cd-9a0e-9a4062b639bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n",
            "[Errno 2] No such file or directory: 'PATH_TO_DATA_DIRECTORY'\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training data\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/train.csv')\n",
        "\n",
        "# Display the first few rows of the training data\n",
        "print(train_df.head())\n",
        "\n",
        "# Summary statistics of the target variable\n",
        "print(train_df['target'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU0KbdQlowBq",
        "outputId": "76e06e93-5e64-44bd-ffa0-116d7b75fc06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sequence     target\n",
            "0   0  MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...  43.329788\n",
            "1   4  MCSLGLFPPPPPRGQVTLYEHNNELVTGSSYESPPPDFRGQWINLP...  51.782791\n",
            "2   5  MSKEERPGREEILECQVMWEPDSKKNTQMDRFRAAVGAACGLALES...  45.080222\n",
            "3   6  MRSSCVLLTALVALAAYYVYIPLPGSVSDPWKLMLLDATFRGAQQV...  59.651078\n",
            "4   7  MNYARFITAASAARNPSPIRTMTDILSRGPKSMISLAGGLPNPNMF...  55.985467\n",
            "count    8148.000000\n",
            "mean       52.302745\n",
            "std         4.738780\n",
            "min        38.520141\n",
            "25%        48.608375\n",
            "50%        51.620779\n",
            "75%        55.496006\n",
            "max        69.875198\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test_df = pd.read_csv('/content/gdrive/MyDrive/test.csv')\n",
        "\n",
        "# Display the first few rows of the test data\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g3NR5RPo52G",
        "outputId": "41a0074f-004b-43a8-b6f9-a0fe9db6aa6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sequence\n",
            "0   1  MALVFVYGTLKRGQPNHRVLRDGAHGSAAFRARGRTLEPYPLVIAG...\n",
            "1   2  MGKNKLLHPSLVLLLLVLLPTDASVSGKPQYMVLVPSLLHTETTEK...\n",
            "2   3  MWAQLLLGMLALSPAIAEELPNYLVTLPARLNFPSVQKVCLDLSPG...\n",
            "3   8  MAAGVPCALVTSCSSVFSGDQLVQHILGTEDLIVEVTSNDAVRFYP...\n",
            "4  11  MESESESGAAADTPPLETLSFHGDEEIIEVVELDPGPPDPDDLAQE...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Adjust the generate_kmer_features function to only transform the data\n",
        "def generate_kmer_features(data, vectorizer=None, k=3):\n",
        "    # Convert sequences to k-mers\n",
        "    data['kmer_sequence'] = data['sequence'].apply(lambda x: [x[i:i+k] for i in range(len(x)-k+1)])\n",
        "    data['kmer_sequence'] = data['kmer_sequence'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    if vectorizer is None:\n",
        "        # If no vectorizer is provided, create a new one and fit it\n",
        "        vectorizer = CountVectorizer()\n",
        "        features = vectorizer.fit_transform(data['kmer_sequence'])\n",
        "    else:\n",
        "        # If a vectorizer is provided, use it to transform the data\n",
        "        features = vectorizer.transform(data['kmer_sequence'])\n",
        "\n",
        "    return features, vectorizer\n"
      ],
      "metadata": {
        "id": "FBNGwkotpC1f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate k-mer features for the training data\n",
        "X_train, vectorizer = generate_kmer_features(train_df, k=3)\n",
        "y_train = train_df['target']\n"
      ],
      "metadata": {
        "id": "7EczJmCG4T7t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gradient Boosting model\n",
        "model = GradientBoostingRegressor()\n",
        "\n",
        "# Define a simpler parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'learning_rate': [0.1],\n",
        "    'max_depth': [3]\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation, using fewer folds and parallel jobs\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Select the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "predictions = best_model.predict(X_val)\n",
        "mse = mean_squared_error(y_val, predictions)\n",
        "print(f'Mean Squared Error on Validation Set: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZL8CSTzzQSO",
        "outputId": "ba25aee6-5c71-4540-fed4-ac43c77857e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error on Validation Set: 17.50510916265811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate k-mer features for the test data\n",
        "X_test, _ = generate_kmer_features(test_df, vectorizer=vectorizer, k=3)\n",
        "\n",
        "# Predict the target variable for the test data\n",
        "test_predictions = best_model.predict(X_test)\n",
        "\n",
        "# Create a DataFrame with the predictions and the 'id' column from the test data\n",
        "predictions_df = pd.DataFrame({'id': test_df['id'], 'target': test_predictions})\n",
        "\n",
        "# Save the DataFrame to a .csv file\n",
        "predictions_file_path = '/content/gdrive/MyDrive/test_predictions.csv'\n",
        "predictions_df.to_csv(predictions_file_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to '{predictions_file_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DOnHcuO-g68",
        "outputId": "fba7c066-9509-4dd9-ecc9-131e2f1d0dbd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to '/content/gdrive/MyDrive/test_predictions.csv'\n"
          ]
        }
      ]
    }
  ]
}